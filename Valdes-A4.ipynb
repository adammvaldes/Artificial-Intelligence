{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Solution to the Towers of Hanoi Puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, you will use reinforcement learning to solve the [Towers of Hanoi](https://en.wikipedia.org/wiki/Tower_of_Hanoi) puzzle with three pegs and five disks.\n",
    "\n",
    "To accomplish this, you must modify the code discussed in lecture for learning to play Tic-Tac-Toe.  Modify the code  so that it learns to solve the three-disk, three-peg\n",
    "Towers of Hanoi Puzzle.  In some ways, this will be simpler than the\n",
    "Tic-Tac-Toe code.  \n",
    "\n",
    "Steps required to do this include the following:\n",
    "\n",
    "  - Represent the state, and use it as a tuple as a key to the Q dictionary.\n",
    "  - Make sure only valid moves are tried from each state.\n",
    "  - Assign reinforcement of $1$ to each move, even for the move that results in the goal state.\n",
    "\n",
    "Make a plot of the number of steps required to reach the goal for each\n",
    "trial.  Each trial starts from the same initial state.  Decay epsilon\n",
    "as in the Tic-Tac-Toe code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, how should we represent the state of this puzzle?  We need to keep track of which disks are on which pegs. Name the disks 1, 2, 3, 4, and 5, with 1 being the smallest disk and 5 being the largest. The set of disks on a peg can be represented as a list of integers.  Then the state can be a list of three lists.\n",
    "\n",
    "For example, the starting state with all disks being on the left peg would be `[[1, 2, 3, 4, 5], [], []]`.  After moving disk 1 to peg 2, we have `[[2, 3, 4, 5], [1], []]`.\n",
    "\n",
    "To represent that move we just made, we can use a list of two peg numbers, like `[1, 2]`, representing a move of the top disk on peg 1 to peg 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to some functions. Define at least the following functions. Examples showing required output appear below.\n",
    "\n",
    "   - `print_state(state)`: prints the state in the form shown below\n",
    "   - `get_valid_moves(state)`: returns list of moves that are valid from `state`\n",
    "   - `make_move(state, move)`: returns new (copy of) state after move has been applied.\n",
    "   - `train_Q(n_repetitions, learning_rate, epsilon_decay_factor, get_valid_moves, make_move)`: train the Q function for number of repetitions, decaying epsilon at start of each repetition. Returns Q and list or array of number of steps to reach goal for each repetition.\n",
    "   - `test_Q(Q, max_steps, get_valid_moves, make_move)`: without updating Q, use Q to find greedy action each step until goal is found. Return path of states.\n",
    "\n",
    "A function that you might choose to implement is\n",
    "\n",
    "   - `state_move_tuple(state, move)`: returns tuple of state and move.  \n",
    "    \n",
    "This is useful for converting state and move to a key to be used for the Q dictionary.\n",
    "\n",
    "Show the code and results for testing each function.  Then experiment with various values of `n_repetitions`, `learning_rate`, and `epsilon_decay_factor` to find values that work reasonably well, meaning that eventually the minimum solution path of seven steps is found consistently.\n",
    "\n",
    "Make a plot of the number of steps in the solution path versus number of repetitions. The plot should clearly show the number of steps in the solution path eventually reaching the minimum of seven steps, though the decrease will not be monotonic.  Also plot a horizontal, dashed line at a height (value on  y axis) of 30 to show the optimal path length.\n",
    "\n",
    "Use at least a total of 15 sentences to describe the following results:\n",
    "- Add markdown cells in which you describe the Q learning algorithm and your implementation of Q learning as applied to the Towers of Hanoi problem.\n",
    "- Add code cells to examine several Q values from the start state with different moves and discuss if the Q values  make sense. \n",
    "- Also add code cells to examine several Q values from one or two states that are two steps away from the goal and discuss if these Q values make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def print_state(state):\n",
    "    print_string = \"\"\n",
    "    #need to use deepcopy to avoid modifying original state\n",
    "    filler_state = copy.deepcopy(state)\n",
    "    #pad out each entry in state with spaces so all the lists are the same length\n",
    "    for i in range(len(filler_state)):\n",
    "        if len(filler_state[i]) < 5:\n",
    "            for j in range(5-len(filler_state[i])):\n",
    "                #print(\"filler state before\")\n",
    "                filler_state[i].insert(0, \" \")\n",
    "    #put together the return string taking the ith index of every list for each column\n",
    "    for i in range(5):\n",
    "        for j in range(len(filler_state)):\n",
    "            print_string += str(filler_state[j][i]) + \" \"\n",
    "        print_string += \"\\n\"\n",
    "    print_string += \"------\"\n",
    "    print(print_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_moves(state):\n",
    "    moves = []\n",
    "    for i in range(len(state)):\n",
    "        for j in range(len(state)):\n",
    "            #if there are no disks on current the peg do nothing\n",
    "            if len(state[i]) == 0:\n",
    "                pass\n",
    "            #if the target peg has no disks then it is a valid move\n",
    "            elif len(state[j]) == 0:\n",
    "                moves.append([i+1,j+1])\n",
    "            #if the top disk on the current peg is less than the top disk of the target peg it is a valid move\n",
    "            elif state[i][0] < state[j][0]:\n",
    "                moves.append([i+1,j+1])\n",
    "    return moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_move(state, move):\n",
    "    state_copy = state.copy()\n",
    "    #assuming all moves passed to function are valid, and it is by human indices (0->1)\n",
    "    state_copy[move[1]-1].insert(0, state_copy[move[0]-1].pop(0))\n",
    "    return state_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convenience function for converting state and move to a formatted tuple\n",
    "def state_move_tuple(state, move):\n",
    "    return (tuple([tuple(ele) for ele in state]), tuple(move))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#epsilonGreedy adapted from lecture notes 15\n",
    "def epsilonGreedy(epsilon, Q, board):\n",
    "    validMoves = get_valid_moves(board)\n",
    "    if np.random.uniform() < epsilon:\n",
    "        #random move\n",
    "        return validMoves[np.random.choice(len(validMoves))]\n",
    "    else:\n",
    "        #greedy move\n",
    "        Qs = np.array([Q.get(state_move_tuple(board, m), 0) for m in validMoves])\n",
    "        #using argmin here instead of argmax because we are solving towers of hanoi and trying to minimize\n",
    "        return validMoves[ np.argmin(Qs) ]\n",
    "\n",
    "#train_Q adapted from lecture notes 15\n",
    "def train_Q(n_repetitions, learning_rate, epsilon_decay_factor, get_valid_moves, make_move):\n",
    "    #goal is to move all pegs to the right peg/3rd peg\n",
    "    Q = {} #empty table\n",
    "    # list of steps taken in each repetition\n",
    "    steps = []\n",
    "    #initial epsilon is 1\n",
    "    epsilon = 1.0\n",
    "    #iterate n_repetition times\n",
    "    for repetition in range(n_repetitions):\n",
    "        #each repetition decays epsilon\n",
    "        epsilon *= epsilon_decay_factor\n",
    "        step = 0\n",
    "        #start state is all disks in order on the left peg\n",
    "        board = [[1, 2, 3, 4, 5], [], []]\n",
    "        #boolean tracker for if the goal is found\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            #increment number of steps taken\n",
    "            step += 1\n",
    "            #each step make a move chosen using epsilonGreedy\n",
    "            move = epsilonGreedy(epsilon, Q, board)\n",
    "            #use deepcopy to utilize a copy without affecting the original\n",
    "            boardNew = copy.deepcopy(board)\n",
    "            boardNew = make_move(boardNew, move)\n",
    "            \n",
    "            if state_move_tuple(board, move) not in Q:\n",
    "                #initial Q value for new board,move is 0, will grow over time\n",
    "                Q[state_move_tuple(board, move)] = 0\n",
    "            #if all disks are in the correct order on the right peg then we won!\n",
    "            if boardNew == [[],[],[1,2,3,4,5]]:\n",
    "                #assign a reinforcement value of 1 even for reaching the goal (as per the instructions)\n",
    "                Q[state_move_tuple(board, move)] = 1\n",
    "                #since we reached the goal we are done with this repetition\n",
    "                done = True\n",
    "                #log the number of steps taken this repetition and append it to the list\n",
    "                steps.append(step)\n",
    "            if step > 1:\n",
    "                #recalculate Q value\n",
    "                Q[state_move_tuple(boardOld, moveOld)] += learning_rate * (1+ Q[state_move_tuple(board, move)] - Q[state_move_tuple(boardOld, moveOld)])\n",
    "            #switch out the previous board and move for the next ones\n",
    "            boardOld, moveOld = board, move\n",
    "            board = boardNew\n",
    "    #return the Q values and the number of steps taken for each repetition\n",
    "    return Q, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Q(Q, max_steps, get_valid_moves, make_move):\n",
    "    board = [[1, 2, 3, 4, 5], [], []]\n",
    "    path = []\n",
    "    #start logging the path taken\n",
    "    path.append(board)\n",
    "    #track number of steps and check they are below max_steps\n",
    "    num_steps = 0\n",
    "    #make moves until the goal is found or we take too long (num_steps >= max_steps)\n",
    "    while board != [[],[],[1,2,3,4,5]] and num_steps < max_steps:\n",
    "        #now that our Q values have been trained we just take the greedy move every move\n",
    "        validMoves = get_valid_moves(board)\n",
    "        Qs = np.array([Q.get(state_move_tuple(board, m), 0) for m in validMoves])\n",
    "        board = copy.deepcopy(make_move(board, validMoves[ np.argmin(Qs) ]))\n",
    "        path.append(board)\n",
    "        num_steps+=1\n",
    "    #some weird adjustments required for the path\n",
    "    path.insert(0, [[1, 2, 3, 4, 5], [], []])\n",
    "    del path[len(path)-1]\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5     \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "state = [[1, 2, 3, 4, 5], [], []]\n",
    "print_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1, 2, 3, 4, 5), (), ()), (1, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move =[1, 2]  # Move top (smallest) disk from first peg to second peg\n",
    "state_move_tuple(state, move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 5], [1], []]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state = make_move(state, move)\n",
    "new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3], [2, 1], [2, 3]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_valid_moves(new_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5 1   \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "print_state(new_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, steps_to_goal = train_Q(200, 0.5, 0.7, get_valid_moves, make_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1720,\n",
       " 478,\n",
       " 690,\n",
       " 1426,\n",
       " 1651,\n",
       " 754,\n",
       " 273,\n",
       " 334,\n",
       " 571,\n",
       " 194,\n",
       " 489,\n",
       " 357,\n",
       " 188,\n",
       " 141,\n",
       " 291,\n",
       " 215,\n",
       " 160,\n",
       " 756,\n",
       " 366,\n",
       " 570,\n",
       " 177,\n",
       " 367,\n",
       " 344,\n",
       " 155,\n",
       " 450,\n",
       " 234,\n",
       " 102,\n",
       " 297,\n",
       " 532,\n",
       " 140,\n",
       " 199,\n",
       " 347,\n",
       " 205,\n",
       " 323,\n",
       " 166,\n",
       " 422,\n",
       " 168,\n",
       " 128,\n",
       " 177,\n",
       " 348,\n",
       " 111,\n",
       " 439,\n",
       " 136,\n",
       " 150,\n",
       " 187,\n",
       " 135,\n",
       " 121,\n",
       " 111,\n",
       " 181,\n",
       " 106,\n",
       " 352,\n",
       " 64,\n",
       " 99,\n",
       " 234,\n",
       " 114,\n",
       " 188,\n",
       " 113,\n",
       " 283,\n",
       " 346,\n",
       " 55,\n",
       " 61,\n",
       " 327,\n",
       " 101,\n",
       " 128,\n",
       " 430,\n",
       " 69,\n",
       " 73,\n",
       " 117,\n",
       " 106,\n",
       " 131,\n",
       " 51,\n",
       " 190,\n",
       " 79,\n",
       " 216,\n",
       " 65,\n",
       " 78,\n",
       " 40,\n",
       " 76,\n",
       " 271,\n",
       " 80,\n",
       " 89,\n",
       " 172,\n",
       " 103,\n",
       " 248,\n",
       " 343,\n",
       " 51,\n",
       " 157,\n",
       " 50,\n",
       " 109,\n",
       " 94,\n",
       " 43,\n",
       " 40,\n",
       " 205,\n",
       " 51,\n",
       " 53,\n",
       " 210,\n",
       " 66,\n",
       " 82,\n",
       " 113,\n",
       " 41,\n",
       " 92,\n",
       " 44,\n",
       " 42,\n",
       " 157,\n",
       " 51,\n",
       " 237,\n",
       " 59,\n",
       " 65,\n",
       " 38,\n",
       " 49,\n",
       " 89,\n",
       " 174,\n",
       " 69,\n",
       " 61,\n",
       " 47,\n",
       " 185,\n",
       " 41,\n",
       " 49,\n",
       " 31,\n",
       " 66,\n",
       " 142,\n",
       " 54,\n",
       " 33,\n",
       " 38,\n",
       " 48,\n",
       " 35,\n",
       " 83,\n",
       " 139,\n",
       " 33,\n",
       " 68,\n",
       " 38,\n",
       " 35,\n",
       " 34,\n",
       " 244,\n",
       " 34,\n",
       " 47,\n",
       " 36,\n",
       " 121,\n",
       " 33,\n",
       " 31,\n",
       " 33,\n",
       " 74,\n",
       " 79,\n",
       " 32,\n",
       " 31,\n",
       " 34,\n",
       " 31,\n",
       " 33,\n",
       " 31,\n",
       " 32,\n",
       " 31,\n",
       " 39,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 147,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_to_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = test_Q(Q, 100, get_valid_moves, make_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3, 4, 5], [], []],\n",
       " [[2, 3, 4, 5], [], [1]],\n",
       " [[3, 4, 5], [2], [1]],\n",
       " [[3, 4, 5], [1, 2], []],\n",
       " [[4, 5], [1, 2], [3]],\n",
       " [[1, 4, 5], [2], [3]],\n",
       " [[1, 4, 5], [], [2, 3]],\n",
       " [[4, 5], [], [1, 2, 3]],\n",
       " [[5], [4], [1, 2, 3]],\n",
       " [[5], [1, 4], [2, 3]],\n",
       " [[2, 5], [1, 4], [3]],\n",
       " [[1, 2, 5], [4], [3]],\n",
       " [[1, 2, 5], [3, 4], []],\n",
       " [[2, 5], [3, 4], [1]],\n",
       " [[5], [2, 3, 4], [1]],\n",
       " [[5], [1, 2, 3, 4], []],\n",
       " [[], [1, 2, 3, 4], [5]],\n",
       " [[1], [2, 3, 4], [5]],\n",
       " [[1], [3, 4], [2, 5]],\n",
       " [[], [3, 4], [1, 2, 5]],\n",
       " [[3], [4], [1, 2, 5]],\n",
       " [[3], [1, 4], [2, 5]],\n",
       " [[2, 3], [1, 4], [5]],\n",
       " [[1, 2, 3], [4], [5]],\n",
       " [[1, 2, 3], [], [4, 5]],\n",
       " [[2, 3], [], [1, 4, 5]],\n",
       " [[3], [2], [1, 4, 5]],\n",
       " [[3], [1, 2], [4, 5]],\n",
       " [[], [1, 2], [3, 4, 5]],\n",
       " [[1], [2], [3, 4, 5]],\n",
       " [[1], [], [2, 3, 4, 5]],\n",
       " [[], [], [1, 2, 3, 4, 5]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5     \n",
      "------\n",
      "\n",
      "      \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5   1 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "3     \n",
      "4     \n",
      "5 2 1 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "3     \n",
      "4 1   \n",
      "5 2   \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "      \n",
      "4 1   \n",
      "5 2 3 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "1     \n",
      "4     \n",
      "5 2 3 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "1     \n",
      "4   2 \n",
      "5   3 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "    1 \n",
      "4   2 \n",
      "5   3 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "    1 \n",
      "    2 \n",
      "5 4 3 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "      \n",
      "  1 2 \n",
      "5 4 3 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "      \n",
      "2 1   \n",
      "5 4 3 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "1     \n",
      "2     \n",
      "5 4 3 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "1     \n",
      "2 3   \n",
      "5 4   \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "      \n",
      "2 3   \n",
      "5 4 1 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "  2   \n",
      "  3   \n",
      "5 4 1 \n",
      "------\n",
      "\n",
      "      \n",
      "  1   \n",
      "  2   \n",
      "  3   \n",
      "5 4   \n",
      "------\n",
      "\n",
      "      \n",
      "  1   \n",
      "  2   \n",
      "  3   \n",
      "  4 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "  2   \n",
      "  3   \n",
      "1 4 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "      \n",
      "  3 2 \n",
      "1 4 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "    1 \n",
      "  3 2 \n",
      "  4 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "    1 \n",
      "    2 \n",
      "3 4 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "      \n",
      "  1 2 \n",
      "3 4 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "      \n",
      "2 1   \n",
      "3 4 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "1     \n",
      "2     \n",
      "3 4 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "1     \n",
      "2   4 \n",
      "3   5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "    1 \n",
      "2   4 \n",
      "3   5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "    1 \n",
      "    4 \n",
      "3 2 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "      \n",
      "  1 4 \n",
      "3 2 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "    3 \n",
      "  1 4 \n",
      "  2 5 \n",
      "------\n",
      "\n",
      "      \n",
      "      \n",
      "    3 \n",
      "    4 \n",
      "1 2 5 \n",
      "------\n",
      "\n",
      "      \n",
      "    2 \n",
      "    3 \n",
      "    4 \n",
      "1   5 \n",
      "------\n",
      "\n",
      "    1 \n",
      "    2 \n",
      "    3 \n",
      "    4 \n",
      "    5 \n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in path:\n",
    "    print_state(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of repetitions')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(steps_to_goal)\n",
    "plt.axhline(y=31, color='r', ls=':')\n",
    "plt.ylabel('Number of steps in solution path')\n",
    "plt.xlabel('Number of repetitions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Part 1: Plot of the results\n",
    "\n",
    "The plot of the number of steps in the solution path versus the number of repetitions is available directly above. The red dashed line is y=31, indicating the minimum number of steps in the solution path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Part 2: Description of the Q learning algorithm and implementation\n",
    "\n",
    "This implementation of Q learning algorithm seeks to represent the (state, move) tuples in this problem with a discrete value.  This value can be called the reinforcement value, temporal difference value or Q value.  This value should represent the estimate of the return of making the given move at the given state.  In this instance, states and moves nearer to the goal should have reinforcement values closer to 1 than those further away from the goal.  In the Towers of Hanoi problem I implemented, the start state was all the disks in order on the leftmost peg, and the goal state was all the disks in order of the rightmost peg.  In this implementation each move made was based on the epsilon-greedy policy, as seen in lecture 15.  In the epsilon-greedy policy, each repetition of finding the goal decreased a value epsilon by a certain amount (the epsilon decay factor).  This value epsilon is what controlled the policy for making moves: at higher epsilon values the policy would be more likely to choose a random move, and once lower epsilon values were reached (at higher repetition counts) the policy would be more likely to choose to make greedy moves.  The greedy-style moves relied on the reinforcement value stored: if a greedy move was performed, it would choose the move with the lowest reinforcement value, which in this case, would (hopefully) be closer to the goal.  This policy works to fill in the reinforcement values for new (state, move) tuples towards the beginning by choosing randomly and eventually fine-tune those values towards their correct values as time goes on and more greedy moves are chosen.  Eventually, once epsilon became low enough, greedy moves were chosen more often.  At this point the reinforcement values for the (state, move) tuples were were accurate enough to give the correct move towards the goal consistently.  As such, as seen in the graph above, the number of steps taken to reach the goal trended downward as the reinforcement values were filled in over time and greedy moves were chosen more often.  As is noted in the code cells above, my train_Q function was adapted from lecture notes 15.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:\n",
      "1     \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5     \n",
      "------\n",
      "Move: (1,2)\n",
      "Q value: 31.049352734685833\n",
      "\n",
      "State:\n",
      "1     \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5     \n",
      "------\n",
      "Move: (1,3)\n",
      "Q value: 31.0\n",
      "\n",
      "State:\n",
      "      \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5   1 \n",
      "------\n",
      "Move: (1,2)\n",
      "Q value: 30.0\n",
      "\n",
      "State:\n",
      "      \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5   1 \n",
      "------\n",
      "Move: (3,1)\n",
      "Q value: 30.06180577122334\n",
      "\n",
      "State:\n",
      "      \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5   1 \n",
      "------\n",
      "Move: (3,2)\n",
      "Q value: 30.28776853909548\n"
     ]
    }
   ],
   "source": [
    "#discussion part 3\n",
    "q_state = [[1,2,3,4,5],[],[]]\n",
    "print(\"State:\")\n",
    "print_state(q_state)\n",
    "print(\"Move: (1,2)\")\n",
    "print(\"Q value:\",Q[(((1, 2, 3, 4, 5), (), ()), (1, 2))])\n",
    "\n",
    "q_state = [[1,2,3,4,5],[],[]]\n",
    "print(\"\\nState:\")\n",
    "print_state(q_state)\n",
    "print(\"Move: (1,3)\")\n",
    "print(\"Q value:\",Q[(((1, 2, 3, 4, 5), (), ()), (1, 3))])\n",
    "\n",
    "q_state = [[2,3,4,5],[],[1]]\n",
    "print(\"\\nState:\")\n",
    "print_state(q_state)\n",
    "print(\"Move: (1,2)\")\n",
    "print(\"Q value:\",Q[(((2, 3, 4, 5), (), (1,)), (1, 2))])\n",
    "\n",
    "q_state = [[2,3,4,5],[],[1]]\n",
    "print(\"\\nState:\")\n",
    "print_state(q_state)\n",
    "print(\"Move: (3,1)\")\n",
    "print(\"Q value:\",Q[(((2, 3, 4, 5), (), (1,)), (3, 1))])\n",
    "\n",
    "q_state = [[2,3,4,5],[],[1]]\n",
    "print(\"\\nState:\")\n",
    "print_state(q_state)\n",
    "print(\"Move: (3,2)\")\n",
    "print(\"Q value:\",Q[(((2, 3, 4, 5), (), (1,)), (3, 2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Part 3: Examination of start state code cells\n",
    "\n",
    "Above is a representation of the state, move, and corresponding Q value of some of the starting and adjacent states.  It can be seen that the (state, move) pairs which bring the state closer to the goal have a lower Q value.  In particular the (state, move) pairs which correspond to the path found by test_Q have Q values equal to 32-s, with s being the number of the step in the path.  In the cases shown, it is the move with the lowest Q value per state that is shown in the path, as expected.  This is because the path was generated using the test_Q function, which always uses the greedy policy of always choosing the lowest Q value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:\n",
      "      \n",
      "      \n",
      "    3 \n",
      "    4 \n",
      "1 2 5 \n",
      "------\n",
      "Move: (1,2)\n",
      "Q value: 2.375\n",
      "\n",
      "State:\n",
      "      \n",
      "      \n",
      "    3 \n",
      "    4 \n",
      "1 2 5 \n",
      "------\n",
      "Move: (2,3)\n",
      "Q value: 2.0\n"
     ]
    }
   ],
   "source": [
    "#discussion part 4\n",
    "q_state = [[1],[2],[3,4,5]]\n",
    "print(\"State:\")\n",
    "print_state(q_state)\n",
    "print(\"Move: (1,2)\")\n",
    "print(\"Q value:\",Q[(((1,), (2,), (3, 4, 5)), (1, 2))])\n",
    "\n",
    "q_state = [[1],[2],[3,4,5]]\n",
    "print(\"\\nState:\")\n",
    "print_state(q_state)\n",
    "print(\"Move: (2,3)\")\n",
    "print(\"Q value:\",Q[(((1,), (2,), (3, 4, 5)), (2, 3))])\n",
    "\n",
    "#print all of Q\n",
    "#num = dict(sorted(Q.items(), key=lambda x: x[1]))\n",
    "#for k,v in num.items():\n",
    "#    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Part 4: Examination of near-goal state code cells\n",
    "\n",
    "Above is the representation of the state, move and corresponding Q value of states that are 2 steps away from the goal.  As expected, it can be seen that the move with the lower Q value of 2.0 is the one that leads to the board that is one move away from the goal.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Download and extract `A4grader.py` from [A4grader.tar](http://www.cs.colostate.edu/~anderson/cs440/notebooks/A4grader.tar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "['Valdes-A4.ipynb']\n",
      "Extracting python code from notebook named 'Valdes-A4.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "\n",
      "Testing\n",
      "\n",
      "  state = [[1], [2,3], [4, 5]]\n",
      "  moves = get_valid_moves(state)\n",
      "\n",
      "\n",
      "--- 5/5 points. Correctly returned [[1, 2], [1, 3], [2, 3]]\n",
      "\n",
      "Testing\n",
      "\n",
      "    state = [[], [], [1, 2, 3, 4, 5]]\n",
      "    moves = get_valid_moves(state)\n",
      "\n",
      "\n",
      "--- 5/5 points. Correctly returned [[3, 1], [3, 2]]\n",
      "\n",
      "Testing\n",
      "\n",
      "    state = [[], [], [1, 2, 3, 4, 5]]\n",
      "    new_state = make_move(state, [3, 1])\n",
      "\n",
      "\n",
      "--- 5/5 points. Correctly returned [[1], [], [2, 3, 4, 5]]\n",
      "\n",
      "Testing\n",
      "\n",
      "    state = [[1, 2], [3], [4, 5]]\n",
      "    new_state = make_move(state, [1, 3])\n",
      "\n",
      "\n",
      "--- 5/5 points. Correctly returned [[2], [3], [1, 4, 5]]\n",
      "\n",
      "Testing\n",
      "\n",
      "    Q, steps = train_Q(1000, 0.5, 0.7, get_valid_moves, make_move)\n",
      "\n",
      "\n",
      "--- 10/10 points. Correctly returned list of steps that has 1000 elements.\n",
      "\n",
      "--- 10/10 points. Correctly returned a Q dictionary with at least 700 elements.\n",
      "\n",
      "Testing\n",
      "\n",
      "    path = test_Q(Q, 20, get_valid_moves, make_move)\n",
      "\n",
      "\n",
      "--- 20/20 points. Correctly returned path with fewer than 40 states.\n",
      "\n",
      "======================================================================\n",
      "C:\\Users\\Adam Valdes\\CS 440 Execution Grade is 60 / 60\n",
      "======================================================================\n",
      "\n",
      "                \n",
      "___ / 10 points. Correct plot of the number of steps in the solution path versus the\n",
      "                 number of repetitions.\n",
      "\n",
      "___ / 10 points. Add markdown cells in which you describe the Q learning algorithm\n",
      "                 and your implementation of Q learning as applied to the \n",
      "                 Towers of Hanoi problem.\n",
      "\n",
      "___ / 10 points. Add code cells to examine several Q values from the start state\n",
      "                 with different moves and discuss if the Q values make sense.\n",
      "\n",
      "___ / 10 points. Also add code cells to examine several Q values from one or two states\n",
      "                 that are two steps away from the goal and discuss if these Q values make sense.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "C:\\Users\\Adam Valdes\\CS 440 Additional Grade is __ / 40\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "C:\\Users\\Adam Valdes\\CS 440 FINAL GRADE is  _  / 100\n",
      "======================================================================\n",
      "\n",
      "Extra Credit: Earn one point of extra credit for your code for solving\n",
      "the Towers of Hanoi puzzle with four pegs and five disks and the experiments\n",
      "and discussion of results.\n",
      "\n",
      "C:\\Users\\Adam Valdes\\CS 440 EXTRA CREDIT is 0 / 1\n"
     ]
    }
   ],
   "source": [
    "%run -i A4grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify your code to solve the Towers of Hanoi puzzle with four pegs and five disks.  Name your functions\n",
    "\n",
    "    - print_state_4pegs\n",
    "    - get_valid_moves_4pegs\n",
    "    - make_move_4pegs\n",
    "\n",
    "Find values for number of repetitions, learning rate, and epsilon decay factor for which train_Q learns a Q function that test_Q can use to find the shortest solution path.  Include the output from the successful calls to train_Q and test_Q."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
